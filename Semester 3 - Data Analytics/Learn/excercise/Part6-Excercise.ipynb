{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7766df",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "<span dir=\"rtl\" style=\"font-family:B Nazanin\" align=\"right\">\n",
    "    <h1>فصل سوم: تجزیه و تحلیل داده‌ها</h1>\n",
    "    <h2>تمرین عملی</h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319d198",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "<p style=\"font-family:B Nazanin;\">\n",
    "    دو فایل تحت نام‌های userdata.csv و userdata.json با فرمت‌های csv و json داریم که اطلاعات یک سری افراد در آن ذخیره شده‌اند و می‌خواهیم فرایند ETL را روی این داده‌ها اجرا کنیم. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7f4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\alireza\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\alireza\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\alireza\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\alireza\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alireza\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19c434",
   "metadata": {},
   "source": [
    "### extractions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f561ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3759d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def extract_from_json(file_path):\n",
    "    return pd.read_json(file_path)\n",
    "\n",
    "def extract_from_excel(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def extract_from_xml(file_path):\n",
    "    return pd.read_xml(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9cdb0",
   "metadata": {},
   "source": [
    "### transforms.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f49470c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforms.py\n",
    "# حذف رکوردهای کاملا خالی\n",
    "def drop_record_all_nans(df):\n",
    "    return df.dropna(how = \"all\", axis = 0)\n",
    "\n",
    "# پر کردن فیلدهای خالی\n",
    "def fillna(data):\n",
    "    data.fillna(value = {\n",
    "        'age': data.age.mean(),\n",
    "        'height': data.height.mean(),\n",
    "        'gender': data.gender.mode()[0],\n",
    "        'weight': data.weight.mean(),\n",
    "        'eye_color': data.eye_color.mode()[0],\n",
    "        'salary': data.salary.mean()\n",
    "    }, inplace = True)\n",
    "    return data\n",
    "\n",
    "# حذف نویز\n",
    "def fill_noisy_data(data):\n",
    "    data.loc[data.eye_color.astype('str').str.isnumeric(), 'eye_color'] = data.eye_color.mode()[0]\n",
    "    return data\n",
    "\n",
    "# تغییر فرمت داده‌ای\n",
    "def change_data_types(data):\n",
    "    data.height = round(data.height)\n",
    "    data = data.astype({'age': 'int'})\n",
    "    return data\n",
    "\n",
    "# One-Hot Encoder\n",
    "def one_hot_encoder(data, columns):\n",
    "    return pd.get_dummies(data, columns=columns)\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoding(data, columns):\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "    return data\n",
    "\n",
    "# گسسته‌سازی\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "def k_bins_discretizer(data, columns):\n",
    "    dis = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "    for col in columns:\n",
    "        data[col] = dis.fit_transform(data[col])\n",
    "    return data\n",
    "\n",
    "# حذف ستون‌های مورد نظر\n",
    "def drop_columns(data, columns):\n",
    "    for col in columns:\n",
    "        data.drop(col, axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "import plotly.express as px\n",
    "def check_outlier_column_by_plotly(data, columns):\n",
    "    fig = px.box(data, y = columns)\n",
    "    fig.show()\n",
    "    \n",
    "# حذف داده‌های پرت\n",
    "def remove_weight_outliers(data, min_w, max_w):\n",
    "    df = pd.DataFrame(data)\n",
    "    data = df[(df['weight'] >= min_w) & (df['weight'] <= max_w)]\n",
    "    return data\n",
    "\n",
    "# نرمال‌سازی\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def min_max_scaler(data, columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = columns\n",
    "    return data\n",
    "\n",
    "# استانداردسازی\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def standard_scaler(data, columns):\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data)\n",
    "    data.columns = columns\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4381df",
   "metadata": {},
   "source": [
    "### loads.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fba5ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data, file_path):\n",
    "    data.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44883859",
   "metadata": {},
   "source": [
    "### main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb4a9422",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alireza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:239: FutureWarning:\n",
      "\n",
      "In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from extractions import *\n",
    "# from transforms import *\n",
    "# from loads import *\n",
    "\n",
    "def display_data(data):\n",
    "    print(data)\n",
    "    print(80*\"*\")\n",
    "\n",
    "data = extract_from_csv(\"./data/userdata.csv\")\n",
    "# display_data(data)\n",
    "\n",
    "# حذف رکوردهای کاملا خالی\n",
    "data = drop_record_all_nans(data)\n",
    "# display_data(data)\n",
    "\n",
    "# پر کردن فیلدهای خالی\n",
    "data = fillna(data)\n",
    "# display_data(data)\n",
    "\n",
    "# حذف نویز\n",
    "data = fill_noisy_data(data)\n",
    "# display_data(data)\n",
    "\n",
    "# تغییر فرمت داده‌ای\n",
    "data = change_data_types(data)\n",
    "# display_data(data)\n",
    "\n",
    "# One-Hot Encoder\n",
    "data = one_hot_encoder(data, ['gender'])\n",
    "# display_data(data)\n",
    "\n",
    "# Label Encoding\n",
    "data = label_encoding(data, ['eye_color'])\n",
    "# display_data(data)\n",
    "\n",
    "# گسسته‌سازی\n",
    "data = k_bins_discretizer(data, [['age']])\n",
    "# display_data(data)\n",
    "\n",
    "# حذف ستون‌های مورد نظر\n",
    "data = drop_columns(data, ['name'])\n",
    "# display_data(data)\n",
    "\n",
    "# check_outlier_column_by_plotly(data, ['height', 'weight', 'age'])\n",
    "\n",
    "# حذف داده‌های پرت\n",
    "data = remove_weight_outliers(data, 40, 120)\n",
    "# display_data(data)\n",
    "\n",
    "# نرمال‌سازی\n",
    "data = min_max_scaler(data, ['age', 'height', 'weight', 'eye_color', 'salary', 'gender_female', 'gender_male'])\n",
    "# display_data(data)\n",
    "\n",
    "# استانداردسازی\n",
    "data = standard_scaler(data, ['age', 'height', 'weight', 'eye_color', 'salary', 'gender_female', 'gender_male'])\n",
    "# display_data(data)\n",
    "\n",
    "load(data, './data/targetFile.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
